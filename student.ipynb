{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 4 â€“ Work In Progress\n",
    "\n",
    "* Student name: Greg Osborne\n",
    "* Student pace: self paced / part time\n",
    "* Scheduled project review date/time: 2/7/22\n",
    "* Instructor name: Morgan Jones\n",
    "* Blog post URL: https://medium.com/@gregosborne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The work below is not meant as a final project. It is a developing project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stakeholder: Google\n",
    "# Problem: Some people have a better public perception of Google and it's cheif competitor, Apple. In building a more positive perception for Google.\n",
    "\n",
    "Google's PR and product development departments could benefit from an NLP model that can provide a snapshot of the public's perception of both Google and their competition, Apple. The [insert what the model does here]\n",
    "\n",
    "1. [itemized list]\n",
    "\n",
    "FurPig accepted the challenge and gave the project to Data Scientist Greg Osborne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrames and computation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#The Train/Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#For Categorical Variables\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#For Min/Max Scaling\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Logistic Regression Model\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Scores\n",
    "#from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "#from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# The Confusion Matrix\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "#Decision Tree Analysis\n",
    "#from sklearn.tree import DecisionTreeClassifier \n",
    "#from sklearn import tree\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Import StandardScaler\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import KNeighborsClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Import Bagging Trees\n",
    "#from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "# For XG Boost\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "#Setting DataFrame Display settings\n",
    "pd.set_option(\"display.max_rows\", 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *function_name*: Function description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a dictionary of specified keys with a count as the values, and then\n",
    "#sorts the list from greatest to least.\n",
    "def tally(lst):\n",
    "    tally_dict = {}\n",
    "    for item in lst:\n",
    "        if item not in tally_dict:\n",
    "            tally_dict[item] = 1\n",
    "        else:\n",
    "            tally_dict[item] += 1\n",
    "    #Sorting the dictionaries\n",
    "    count = sorted(tally_dict.items(), key=lambda x:x[1],reverse = True)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Creating a df of nothing but the retweets\n",
    "def retweet_trim_one(dfone):\n",
    "    for i in range(len(dfone)):\n",
    "        twt = dfone.loc[i,'Tokens']\n",
    "        #Twitter parlance: rt = retweet\n",
    "        #Dropping all tweets that don't start in rt\n",
    "        if 'rt' != twt[0]:\n",
    "            dfone.drop(index = i,inplace=True)\n",
    "    return dfone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column that will have the same tokens, just without rt or\n",
    "#mention at the beginning.\n",
    "\n",
    "def retweet_trim_two(dftwo, drop_first_words = ['skip'], drop_num = 1):\n",
    "    #Creating a column to put the trimmed retweet\n",
    "    dftwo['trimmed_rt'] = 'Blank'\n",
    "    dftwo['Match'] = False\n",
    "\n",
    "        \n",
    "    #I want to test the data to see if there's anything that stands out as\n",
    "    #repetitive in the first or second words of the newly trimmed tweets.\n",
    "    #Creating a list of the first and second words of each trimmed tweet.\n",
    "    firstword_lst = []\n",
    "    secondword_lst = []\n",
    "    \n",
    "    #Starting a list to drop any retweets. \n",
    "    retweets_to_drop = []\n",
    "    \n",
    "    for i in dftwo.index:\n",
    "        #making the trimmed variable, the tokens of the next tweet to edit\n",
    "        trimmed = dftwo.at[i,'Tokens']\n",
    "        #Removing the set number of dropped tokens. \n",
    "        #Default is just the first token, \"rt.\"\n",
    "        trimmed = trimmed[drop_num:]\n",
    "        if len(trimmed) == 0:\n",
    "            if drop_num == 1:\n",
    "                retweets_to_drop.append(i)\n",
    "            continue\n",
    "        #Several retweets include 'mention' after the rt, so I'll trim that.\n",
    "        #This while loop quits dropping words with the first token that isn't\n",
    "        #in the drop list specified by parameter.\n",
    "        if drop_first_words != ['skip']:\n",
    "            while trimmed[0] in drop_first_words:\n",
    "                trimmed = trimmed[1:]\n",
    "                #Some tweets contained only \"rt\" and \"mention,\" and are now\n",
    "                #empty.\"\n",
    "                #Adding any empty token lists to the retweets_to_drop list.\n",
    "                if len(trimmed) == 0:\n",
    "                    if drop_num == 1:\n",
    "                        retweets_to_drop.append(i)\n",
    "                    break\n",
    "        if len(trimmed) == 0:\n",
    "            continue\n",
    "        \n",
    "        #Adding first and second words of the trimmed tweet to the lists.\n",
    "        firstword_lst.append(trimmed[0])\n",
    "        secondword_lst.append(trimmed[1])\n",
    "        \n",
    "        #Replacing the trimmed tokens to a new column, \"trimmed_rt\".\n",
    "        dftwo.at[i,'trimmed_rt'] = trimmed\n",
    "    \n",
    "    #I want to test the data to see if there's anything that stands out as\n",
    "    #repetitive in the first word of the newly trimmed tweets.\n",
    "    #Creating a dictionary to count the first word in each trimmed tweet.\n",
    "    \n",
    "    firstword_count = tally(firstword_lst)\n",
    "    secondword_count = tally(secondword_lst)\n",
    "    \n",
    "    return dftwo, firstword_count, secondword_count, retweets_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking to see if any of theses newly trimmed retweets are exact matches of\n",
    "#Original tweets in the dataset.\n",
    "\n",
    "def retweet_trim_three(dfthree, dforg, retweets_to_drop):\n",
    "    original_tweets = []\n",
    "    \n",
    "    for i in dforg.index:\n",
    "        original_tweets.append(dforg.at[i,'Tokens'])\n",
    "    \n",
    "    for i in dfthree.index:\n",
    "        retweet = dfthree.at[i,'trimmed_rt']\n",
    "        if retweet in original_tweets:\n",
    "            dfthree.at[i,'Match'] = True\n",
    "            retweets_to_drop.append(i)\n",
    "    \n",
    "    return dfthree, retweets_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a single function that runs all of the previous functions but allows\n",
    "#a lister parameter to choose what words are filtered out of the first words.\n",
    "def retweet_trim_all(retweets, word_list = ['skip'], delete = True, drop = 1):\n",
    "    retweets = retweet_trim_one(retweets)\n",
    "    retweets, fw, sw, rtd = retweet_trim_two(retweets, word_list, drop)\n",
    "    retweets, rtd = retweet_trim_three(retweets, df, rtd)\n",
    "    #Dropping the tweets.\n",
    "    if delete == False:\n",
    "        print(retweets['Match'].value_counts())\n",
    "        return retweets.loc[retweets['Match'] == True]\n",
    "    df.drop(index = rtd, inplace=True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    return retweets['Match'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data and previewing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beautifully smart and simple idea RT @madebyma...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "5  @teachntech00 New iPad Apps For #SpeechTherapy...   \n",
       "6                                                NaN   \n",
       "7  #SXSW is just starting, #CTIA is around the co...   \n",
       "8  Beautifully smart and simple idea RT @madebyma...   \n",
       "9  Counting down the days to #sxsw plus strong Ca...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "5                             NaN   \n",
       "6                             NaN   \n",
       "7                         Android   \n",
       "8              iPad or iPhone App   \n",
       "9                           Apple   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  \n",
       "5                 No emotion toward brand or product  \n",
       "6                 No emotion toward brand or product  \n",
       "7                                   Positive emotion  \n",
       "8                                   Positive emotion  \n",
       "9                                   Positive emotion  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"judge-1377884607_tweet_product_company.csv\", \n",
    "                     encoding='ANSI')\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value counts of categorized columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['emotion_in_tweet_is_directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5389\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis and explanation of next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet             Product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            Emotion  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = {'tweet_text' : 'Tweet',\n",
    "        'emotion_in_tweet_is_directed_at':'Product',\n",
    "        'is_there_an_emotion_directed_at_a_brand_or_product': 'Emotion'}\n",
    "df = df_raw.rename(columns=name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa m...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet             Product  \\\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...              iPhone   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...  iPad or iPhone App   \n",
       "2  @swonderlin can not wait for #ipad 2 also. the...                iPad   \n",
       "3  @sxsw i hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on fri #sxsw: marissa m...              Google   \n",
       "\n",
       "            Emotion  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet'] = df['Tweet'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index number 6 is a <class 'float'>, not a string\n"
     ]
    }
   ],
   "source": [
    "#Testing for any Tweets that are not strings\n",
    "bad_tweets = []\n",
    "for i in range(len(df)):\n",
    "    typ = type(df.at[i,'Tweet'])\n",
    "    if typ != str:\n",
    "        print('Index number {} is a {}, not a string'.format(i,typ))\n",
    "        bad_tweets.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa m...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 new ipad apps for #speechtherapy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#sxsw is just starting, #ctia is around the co...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>beautifully smart and simple idea rt @madebyma...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet             Product  \\\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...              iPhone   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...  iPad or iPhone App   \n",
       "2  @swonderlin can not wait for #ipad 2 also. the...                iPad   \n",
       "3  @sxsw i hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on fri #sxsw: marissa m...              Google   \n",
       "5  @teachntech00 new ipad apps for #speechtherapy...                 NaN   \n",
       "6  #sxsw is just starting, #ctia is around the co...             Android   \n",
       "7  beautifully smart and simple idea rt @madebyma...  iPad or iPhone App   \n",
       "\n",
       "                              Emotion  \n",
       "0                    Negative emotion  \n",
       "1                    Positive emotion  \n",
       "2                    Positive emotion  \n",
       "3                    Negative emotion  \n",
       "4                    Positive emotion  \n",
       "5  No emotion toward brand or product  \n",
       "6                    Positive emotion  \n",
       "7                    Positive emotion  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping bad data and reseting the index\n",
    "df.drop(index = bad_tweets, inplace=True)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize\n",
    "The process of tokenizing the data is to turn each tweet into a list, with each element being a single item in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Tokenize library\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "#Creating the tokenizer\n",
    "basic_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "tokenizer = RegexpTokenizer(basic_token_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[wesley83, have, 3g, iphone, after, hrs, tweet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[jessedee, know, about, fludapp, awesome, ipad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[swonderlin, can, not, wait, for, ipad, also, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[sxsw, hope, this, year, festival, isn, as, cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa m...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, on, fri, sxsw, maris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet             Product  \\\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...              iPhone   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...  iPad or iPhone App   \n",
       "2  @swonderlin can not wait for #ipad 2 also. the...                iPad   \n",
       "3  @sxsw i hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on fri #sxsw: marissa m...              Google   \n",
       "\n",
       "            Emotion                                             Tokens  \n",
       "0  Negative emotion  [wesley83, have, 3g, iphone, after, hrs, tweet...  \n",
       "1  Positive emotion  [jessedee, know, about, fludapp, awesome, ipad...  \n",
       "2  Positive emotion  [swonderlin, can, not, wait, for, ipad, also, ...  \n",
       "3  Negative emotion  [sxsw, hope, this, year, festival, isn, as, cr...  \n",
       "4  Positive emotion  [sxtxstate, great, stuff, on, fri, sxsw, maris...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new column for the tokenized tweet\n",
    "df['Tokens'] = None\n",
    "\n",
    "#Creating the token lists\n",
    "for i in range(len(df)):\n",
    "    df['Tokens'][i] = tokenizer.tokenize(df['Tweet'][i])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for duplicate tweets in the form of retweets.\n",
    "There's no need to have the same words analyzed twice, except one begins with \"rt\" and a mention. So, I'll get rid of all retweets that have the original tweet in the dataset.\n",
    "\n",
    "The process of checking for retweets can be done multiple times with slighly different parameters. Sometimes, it's necessary to check for certain words at the beginning. Other times, just trimming the beginning off by a certain number of words is all that's needed. Therefore, I created four functions the make this process simpler. The functions are at the top of this worksheet.\n",
    "\n",
    "The four steps are:\n",
    "1. Create Dataframe with nothing but the retweets, including the tokenized version.\n",
    "2. Trim the retweet by soecified parameters.\n",
    "3. Check to see if there are any exact matches of the trimmed retweets in the original dataset.\n",
    "4. Purge the retweets.\n",
    "\n",
    "The final step is wrapped into another function that performs all of these steps at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rt @laurieshook: i'm looking forward to the #s...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[rt, laurieshook, looking, forward, to, the, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rt haha, awesomely rad ipad app by @madebymany...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[rt, haha, awesomely, rad, ipad, app, by, made...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>rt ' it's 4 p.m. and the #ipad2 line at the ap...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[rt, it, and, the, ipad2, line, at, the, apple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>rt hiring marketers, designers, creatives, soc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[rt, hiring, marketers, designers, creatives, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>l.a.m.e.  rt @mention &amp;quot;...by the law of a...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[rt, mention, quot, by, the, law, of, averages...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  \\\n",
       "24    rt @laurieshook: i'm looking forward to the #s...   \n",
       "25    rt haha, awesomely rad ipad app by @madebymany...   \n",
       "199   rt ' it's 4 p.m. and the #ipad2 line at the ap...   \n",
       "867   rt hiring marketers, designers, creatives, soc...   \n",
       "1054  l.a.m.e.  rt @mention &quot;...by the law of a...   \n",
       "\n",
       "                              Product                             Emotion  \\\n",
       "24                               iPad                    Positive emotion   \n",
       "25                 iPad or iPhone App                    Positive emotion   \n",
       "199                               NaN  No emotion toward brand or product   \n",
       "867                               NaN  No emotion toward brand or product   \n",
       "1054  Other Google product or service                    Negative emotion   \n",
       "\n",
       "                                                 Tokens  \n",
       "24    [rt, laurieshook, looking, forward, to, the, s...  \n",
       "25    [rt, haha, awesomely, rad, ipad, app, by, made...  \n",
       "199   [rt, it, and, the, ipad2, line, at, the, apple...  \n",
       "867   [rt, hiring, marketers, designers, creatives, ...  \n",
       "1054  [rt, mention, quot, by, the, law, of, averages...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a copy of the dataframe.\n",
    "retweets = df.copy()\n",
    "\n",
    "#Purging original tweets from the new copy, so that all that is left\n",
    "#are retweets.\n",
    "retweets = retweet_trim_one(retweets)\n",
    "\n",
    "#Creating an initial count of all retweets\n",
    "retweet_count = len(retweets)\n",
    "\n",
    "#Previewing the retweets.\n",
    "retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trimming the retweets of the first \"rt\" and the subsequent word \"mention.\"\n",
    "retweets, fw, sw, rtd = retweet_trim_two(retweets, ['mention'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1461\n",
       "False     529\n",
       "Name: Match, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking to see if any of the trimmed retweets match any original tweets in\n",
    "#the dataset.\n",
    "retweets, rtd = retweet_trim_three(retweets, df, rtd)\n",
    "\n",
    "#If a the Match column value is True, then the retweet matches an original \n",
    "#tweet and will be deleted in the next cell\n",
    "retweets['Match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the duplicate retweets from the original dataset.\n",
    "df.drop(index = rtd, inplace=True)\n",
    "\n",
    "#Resetting the dataset's index.\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying other methods to identify and delete duplicate tweets.\n",
    "For reasons I don't understand, some of the tweets were retweets of retweets. So I'll check if there were even more retweets of originals in the dataset.\n",
    "\n",
    "First, I decided to expand the key word search at the beginning of each retweet. To do this, I decided to preview what words came up first and second in the previously trimmed retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rt', 162),\n",
       " ('google', 159),\n",
       " ('apple', 92),\n",
       " ('sxsw', 78),\n",
       " ('the', 48),\n",
       " ('we', 42),\n",
       " ('quot', 41),\n",
       " ('at', 36),\n",
       " ('just', 30),\n",
       " ('new', 29)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A list of the top ten first words after the previous trimming.\n",
    "fw[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mention', 226),\n",
       " ('to', 127),\n",
       " ('sxsw', 77),\n",
       " ('is', 58),\n",
       " ('google', 49),\n",
       " ('the', 44),\n",
       " ('you', 40),\n",
       " ('ipad', 30),\n",
       " ('apple', 27),\n",
       " ('of', 26)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A list of the top ten second words after the previous trimming.\n",
    "sw[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list above, I tried multiple combinations of the more popular, significant, words to see if trimming those words found more matches to the orginal tweets in the dataset. After several combinations of the words \"mention, sxsw, google, apple, rt, and quot,\" the two combinations below were the only two that found any matches at all. Together, they found four matches and deleted all four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    527\n",
       "True       1\n",
       "Name: Match, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Before each run through these functions, I need to make a new copy of the \n",
    "#retweets DafaFrame.\n",
    "retweets = df.copy()\n",
    "\n",
    "#Checking for multiple subsequent copies of both \"rt\" and \"mention.\"\n",
    "retweet_trim_all(retweets, ['rt','mention'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    524\n",
       "True       3\n",
       "Name: Match, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for multiple subsequent copies of just \"rt.\"\n",
    "retweets = df.copy()\n",
    "retweet_trim_all(retweets, ['rt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A strange thing about this dataset, is it seems clear that the word \"mention\" is used in lieu of the user's name. The metadata to the dataset contained no explanation as to why this is happening, but I suspect it's to protect the user's privacy. However, the whole set is not like this. Several tweets do contain the @ symbol followed by a twitter username. So several tweets begin \"rt @username\" with the username being specific to the person being retweeted. \n",
    "\n",
    "This means that I should try to remove the first two words from every tweet that begins with \"rt\" and check those for matches with the original data. When I added a parameter to my functions to do just that, it dawned on me that there might be other reasons to try a strict number approach to testing for originals. There could be a reason where deletion of the first five tokens will result in a match with the original tweet. I decided to not just look at removing the first two tokens, but sequentually previewing all the way up to the first seven tokens to check for matches.\n",
    "\n",
    "Below I did just that. I preview the results before committing to the change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retweets = df.copy()\n",
    "retweet_trim_all(retweets, delete = False, drop = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retweets = df.copy()\n",
    "retweet_trim_all(retweets, delete = False, drop = 2).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retweets = df.copy()\n",
    "retweet_trim_all(retweets, delete = False, drop = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retweets = df.copy()\n",
    "retweet_trim_all(retweets, delete = False, drop = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retweets = df.copy()\n",
    "retweet_trim_all(retweets, delete = False, drop = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retweets = df.copy()\n",
    "retweet_trim_all(retweets, delete = False, drop = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retweets = df.copy()\n",
    "retweet_trim_all(retweets, delete = False, drop = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets that match by removing seven words would remove words that add context to the original tweet, and six words has no matches, so I'll just delete the rows that match original tweets after deleting the second through fifth words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing matches that occur when removing the first two through the first\n",
    "#five words\n",
    "\n",
    "#Variable to count the number of words deleted\n",
    "deleted = 0\n",
    "retweets = df.copy()\n",
    "\n",
    "#Variable that tells me how many retweets we're analyzing in this way.\n",
    "started = len(retweet_trim_one(retweets))\n",
    "\n",
    "#Removing the sencond through fifth words, checking for matches, and deleting\n",
    "#the matched retweets from the dataset.\n",
    "for i in range(2,6):\n",
    "    retweets = df.copy()\n",
    "    retweet_trim_all(retweets, drop = i)\n",
    "    deleted += len(retweets.loc[retweets['Match'] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial purge deleted 1466 retweets that already existed in the dataset\n",
      "once all instances of both \"rt\" and \"mention\" were deleted from the\n",
      "beginning of each retweet.\n",
      "\n",
      "After this inital purge, there were 524 retweets remaining.\n",
      "The above cell found, and deleted, 74 additional retweets that matched\n",
      "original tweets.\n",
      "In total, I deleted 1540 out of 1990 retweets.\n",
      "1540 deleted tweets out of 9093 tweets in the dataset is 16.94% of the data.\n",
      "\n",
      "There are now 7553 tweets remaining in the dataset\n"
     ]
    }
   ],
   "source": [
    "initial_purge = retweet_count - started\n",
    "tot_del = retweet_count - started + deleted\n",
    "per_det = round(tot_del/len(df_raw)*10000)/100\n",
    "new_tot = len(df_raw) - tot_del\n",
    "\n",
    "#Putting the process above into words.\n",
    "print('The initial purge deleted', initial_purge,\n",
    "      'retweets that already existed in the dataset')\n",
    "print('once all instances of both \"rt\" and \"mention\" were deleted from the')\n",
    "print('beginning of each retweet.')\n",
    "print()\n",
    "print('After this inital purge, there were', started, 'retweets remaining.')\n",
    "print('The above cell found, and deleted,', deleted,\n",
    "      'additional retweets that matched')\n",
    "print('original tweets.')\n",
    "print('In total, I deleted', tot_del,\n",
    "     'out of', retweet_count , 'retweets.')\n",
    "print(tot_del, 'deleted tweets out of', len(df_raw),\n",
    "      'tweets in the dataset is {}% of the data.'.format(per_det))\n",
    "print()\n",
    "print('There are now', new_tot,\n",
    "      'tweets remaining in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good rule of thumb for pruning datasets is not to delete 10% of the data, but I've already deleted more than that. However, I would argue that I have not. I have deleted duplicate data with a few additional words that provide very little context. I will follow the 10% rule from this point forward. I will not delete an additional 10% of the data from what I've already deleted.\n",
    "\n",
    "The retweet purge is now complete. I'll now move on to categorizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking what products are mentioned in the tweets\n",
    "Now that so many retweets have been purged, I'll look at some summaries of the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7552 entries, 0 to 7551\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Tweet    7552 non-null   object\n",
      " 1   Product  2795 non-null   object\n",
      " 2   Emotion  7552 non-null   object\n",
      " 3   Tokens   7552 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 236.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 7552 remaining tweets 4757 do not have a label in the Products column.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "iPad                               821\n",
       "Apple                              561\n",
       "iPad or iPhone App                 384\n",
       "Google                             351\n",
       "iPhone                             266\n",
       "Other Google product or service    235\n",
       "Android App                         75\n",
       "Android                             71\n",
       "Other Apple product or service      31\n",
       "Name: Product, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting the number of rows that have products labeled:\n",
    "products_labeled = len(df.loc[df['Product'].notna()])\n",
    "print('Of the', len(df), 'remaining tweets', len(df) - products_labeled, \n",
    "     'do not have a label in the Products column.')\n",
    "\n",
    "df['Product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still a lot of rows that do not have the product the tweet discusses labeled. To fix this, I'm going to do a word search for different products these two companies make, Apple and Google. I'll use this keyword search to identify which company the tweets discuss, Apple or Google. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying any tweets with the following words:\n",
      "['Apple', 'iPad', 'iPads', 'iPad2', 'iPhone', 'iTunes', 'iPhone5', 'iTune', 'Laptop', 'Store', 'Google', 'Android', 'Droid', 'Circles', 'Blogger', 'Maps']\n",
      "\n",
      "There are 562 tweets that don't have any of the above words\n"
     ]
    }
   ],
   "source": [
    "#Keywords that I'll use to identify what product the tweet discusses.\n",
    "keywords_apple = ['Apple', 'iPad', 'iPads', 'iPad2', 'iPhone', 'iTunes',\n",
    "                  'iPhone5', 'iTune', 'Laptop', 'Store']\n",
    "#Google did not make laptops in March 2011, so the laptops are Apple.\n",
    "\n",
    "keywords_google = ['Google', 'Android', 'Droid', 'Circles', 'Blogger', 'Maps']\n",
    "keywords_all = keywords_apple + keywords_google\n",
    "\n",
    "#A list of index numbers that do not have any of the products listed.\n",
    "noprod = []\n",
    "\n",
    "#Create a column for each keyword, to be purged later.\n",
    "for word in keywords_all:\n",
    "    df[word] = False\n",
    "\n",
    "#Labeling each tweet with what keywords they include.\n",
    "for i in range(len(df)):\n",
    "    for word in keywords_all:\n",
    "        if word.lower() in df['Tokens'][i]:\n",
    "            df.at[i,word] = True\n",
    "            \n",
    "    #appending noprod with the index number of all rows without any keywords.\n",
    "    if sum(df.iloc[i,4:].values) == 0:\n",
    "        noprod.append(i)\n",
    "\n",
    "print('Identifying any tweets with the following words:')\n",
    "print(keywords_all)\n",
    "print()\n",
    "print(\"There are {} tweets that don't have any of the above words\".format(\n",
    "    len(noprod)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to identify these tweets as discussing either Apple or Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing tweets by either Apple or Google\n",
    "I'm not sure how much I trust the given Product column since it doesn't label several rows. First, I'll label the rows as either \"Apple\", \"Google\" or \"Both\" based on the key words I already gleaned from the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Apple</th>\n",
       "      <th>iPad</th>\n",
       "      <th>iPads</th>\n",
       "      <th>iPad2</th>\n",
       "      <th>iPhone</th>\n",
       "      <th>iTunes</th>\n",
       "      <th>iPhone5</th>\n",
       "      <th>iTune</th>\n",
       "      <th>Laptop</th>\n",
       "      <th>Store</th>\n",
       "      <th>Google</th>\n",
       "      <th>Android</th>\n",
       "      <th>Droid</th>\n",
       "      <th>Circles</th>\n",
       "      <th>Blogger</th>\n",
       "      <th>Maps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[wesley83, have, 3g, iphone, after, hrs, tweet...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[jessedee, know, about, fludapp, awesome, ipad...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[swonderlin, can, not, wait, for, ipad, also, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[sxsw, hope, this, year, festival, isn, as, cr...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa m...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, on, fri, sxsw, maris...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet             Product  \\\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...              iPhone   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...  iPad or iPhone App   \n",
       "2  @swonderlin can not wait for #ipad 2 also. the...                iPad   \n",
       "3  @sxsw i hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on fri #sxsw: marissa m...              Google   \n",
       "\n",
       "            Emotion                                             Tokens  Apple  \\\n",
       "0  Negative emotion  [wesley83, have, 3g, iphone, after, hrs, tweet...  False   \n",
       "1  Positive emotion  [jessedee, know, about, fludapp, awesome, ipad...  False   \n",
       "2  Positive emotion  [swonderlin, can, not, wait, for, ipad, also, ...  False   \n",
       "3  Negative emotion  [sxsw, hope, this, year, festival, isn, as, cr...  False   \n",
       "4  Positive emotion  [sxtxstate, great, stuff, on, fri, sxsw, maris...  False   \n",
       "\n",
       "    iPad  iPads  iPad2  iPhone  iTunes  iPhone5  iTune  Laptop  Store  Google  \\\n",
       "0  False  False  False    True   False    False  False   False  False   False   \n",
       "1   True  False  False    True   False    False  False   False  False   False   \n",
       "2   True  False  False   False   False    False  False   False  False   False   \n",
       "3  False  False  False    True   False    False  False   False  False   False   \n",
       "4  False  False  False   False   False    False  False   False  False    True   \n",
       "\n",
       "   Android  Droid  Circles  Blogger   Maps  \n",
       "0    False  False    False    False  False  \n",
       "1    False  False    False    False  False  \n",
       "2    False  False    False    False  False  \n",
       "3    False  False    False    False  False  \n",
       "4    False  False    False    False  False  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple      4495\n",
       "Google     2272\n",
       "Unknown     562\n",
       "Both        223\n",
       "Name: Company, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This cell labels each row as \"Apple\", \"Google\", \"Both\" or \"Unknown\"\n",
    "df['Company'] = 'Blank'\n",
    "for i in range(len(df)):\n",
    "    #Checking for \"Apple\"\n",
    "    for col in keywords_apple:\n",
    "        if df[col][i]:\n",
    "            df.at[i,'Company'] = 'Apple'\n",
    "            #Checking for both Apple and Google\n",
    "            for goog in keywords_google:\n",
    "                if df[goog][i]:\n",
    "                    df.at[i,'Company'] = 'Both'\n",
    "                    break\n",
    "            break\n",
    "    #Checking for \"Google\"\n",
    "    if df.at[i,'Company'] not in ['Apple', 'Both']:\n",
    "        for goog in keywords_google:\n",
    "            if df[goog][i]:\n",
    "                df.at[i,'Company'] = 'Google'\n",
    "                break\n",
    "    #Checking for Unknowns\n",
    "    if df.at[i,'Company'] not in ['Apple', 'Both', 'Google']:\n",
    "        df.at[i,'Company'] = 'Unknown'\n",
    "df['Company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 7552 tweets, 223 are labeled as \"Both\", 2.95% of the remaining data.\n"
     ]
    }
   ],
   "source": [
    "num_both = len(df.loc[df['Company'] == 'Both'])\n",
    "print('Out of', len(df), 'tweets,', num_both,\n",
    "     'are labeled as \"Both\", {}% of the'.format(\n",
    "     round((num_both/len(df))*10000)/100),\n",
    "     'remaining data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are so few that are labeled as \"Both\", I think I'll just drop them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple      4495\n",
       "Google     2272\n",
       "Unknown     562\n",
       "Name: Company, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(index = df.loc[df['Company']=='Both'].index, inplace=True)\n",
    "df['Company'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Product column against Company Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think it's possible that some of the tweets that don't have any of the keywords do have a product label. If so, I can identify which company they discuss via the provided product label rather than the keywords.\n",
    "\n",
    "First, I'm going to check if the product labels match my keyward search for company. To do this, I'll create a new column, \"Company by Product\" which will include the company name gleaned soley from the Product column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apple = ['iPad', 'Apple', 'iPad or iPhone App',\n",
    "         'iPhone', 'Other Apple product or service']\n",
    "Google = ['Google', 'Other Google product or service',\n",
    "          'Android App', 'Android']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Google</th>\n",
       "      <th>Android</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa m...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet             Product  \\\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...              iPhone   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...  iPad or iPhone App   \n",
       "2  @swonderlin can not wait for #ipad 2 also. the...                iPad   \n",
       "3  @sxsw i hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on fri #sxsw: marissa m...              Google   \n",
       "\n",
       "            Emotion  Google  Android  \n",
       "0  Negative emotion   False    False  \n",
       "1  Positive emotion   False    False  \n",
       "2  Positive emotion   False    False  \n",
       "3  Negative emotion   False    False  \n",
       "4  Positive emotion    True    False  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the \"Company by Product\" column and populating it based on the \n",
    "#Product column\n",
    "df['Company by Product'] = df['Product'].map(\n",
    "    lambda x : 'Apple' if x in Apple else np.nan)\n",
    "possgoog = df['Company by Product'] != 'Apple'\n",
    "\n",
    "df.loc[possgoog,'Company by Product'] = df.loc[possgoog, 'Product'].map(\n",
    "    lambda x : 'Google' if x in Google else np.nan)\n",
    "df.iloc[0:5,[0,1,2,14,15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Match             2713\n",
       "Apple, nan        2489\n",
       "Google, nan       1562\n",
       "Unknown, nan       552\n",
       "Unknown, Apple      10\n",
       "Google, Apple        3\n",
       "Name: Not Matching, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking which rows don't have matching values in columns \"Company\" and \n",
    "#\"Company by Product\"\n",
    "df['Not Matching'] = \"Match\"\n",
    "for i in df.index:\n",
    "    by_keyword = df.at[i,'Company']\n",
    "    by_product = df.at[i,'Company by Product']\n",
    "    if by_keyword != by_product:\n",
    "        df.at[i,'Not Matching'] = str([by_keyword,\n",
    "                                       by_product])[1:-1].replace(\"'\",\"\")\n",
    "df['Not Matching'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the cells defining the company between *Company* and *Company by Product* columns matched or didn't have data in the second column to match. None of those situations concerns me.\n",
    "\n",
    "There are four tweets that the keyword analysis labeled as Google and given Product column labeled as \"Apple.\" I'll review these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Not Matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>just read about #groupme at #sxsw...sounds like an incredible app. is it available for android phones yet?</td>\n",
       "      <td>Google, Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>all this @mention #sxsw buzz makes me wish i had an android or i-phone.  #beforetwitter i wouldn't have had such envy.</td>\n",
       "      <td>Google, Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>several years too late? i think the trend of social apps is over... @mention  #sxsw #google #circles #conversation @mention</td>\n",
       "      <td>Google, Apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                            Tweet  \\\n",
       "221                    just read about #groupme at #sxsw...sounds like an incredible app. is it available for android phones yet?   \n",
       "1557       all this @mention #sxsw buzz makes me wish i had an android or i-phone.  #beforetwitter i wouldn't have had such envy.   \n",
       "2795  several years too late? i think the trend of social apps is over... @mention  #sxsw #google #circles #conversation @mention   \n",
       "\n",
       "       Not Matching  \n",
       "221   Google, Apple  \n",
       "1557  Google, Apple  \n",
       "2795  Google, Apple  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "df.loc[(df['Not Matching'] == 'Google, Apple'), ['Tweet', 'Not Matching']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three tweets in the set above, 221and 1557, are both clearly both Apple and Google. 2795 is exclusively Google.\n",
    "\n",
    "I'll delete 221 and 1557 and leave 2795 in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Match             2713\n",
       "Apple, nan        2489\n",
       "Google, nan       1562\n",
       "Unknown, nan       552\n",
       "Unknown, Apple      10\n",
       "Google, Apple        1\n",
       "Name: Not Matching, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatch_products = [221, 1557]\n",
    "df.drop(index = mismatch_products, inplace=True)\n",
    "df['Not Matching'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets without any of the key words\n",
    "I'm unsure what the criteria was for assembling this list of tweets. The most common theme seems to be South by Southwest, an annual technology and art expo in Austin. Also, I don't know why so many of the tweets use @mention instead of leaving the identity of the user name. The way twitter works, the @mentions are critical to understand the context of the entire tweet.\n",
    "\n",
    "This being said, I have 585 tweets that contained none of the key words I chose to identify them as either Apple or Google. First, I want to see if any of them were given labels in the given Products column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad or iPhone App    10\n",
       "Name: Product, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a DataFrame of just the tweets that don't have any of the key words.\n",
    "cut_tweets = df.copy()\n",
    "for i in df.index:\n",
    "    if i not in noprod:\n",
    "        cut_tweets.drop(index = i,inplace=True)\n",
    "\n",
    "#Checking if any of these tweets without the key words have a product labeled.\n",
    "cut_tweets['Product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 562 entries, 49 to 7485\n",
      "Data columns (total 23 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Tweet               562 non-null    object\n",
      " 1   Product             10 non-null     object\n",
      " 2   Emotion             562 non-null    object\n",
      " 3   Tokens              562 non-null    object\n",
      " 4   Apple               562 non-null    bool  \n",
      " 5   iPad                562 non-null    bool  \n",
      " 6   iPads               562 non-null    bool  \n",
      " 7   iPad2               562 non-null    bool  \n",
      " 8   iPhone              562 non-null    bool  \n",
      " 9   iTunes              562 non-null    bool  \n",
      " 10  iPhone5             562 non-null    bool  \n",
      " 11  iTune               562 non-null    bool  \n",
      " 12  Laptop              562 non-null    bool  \n",
      " 13  Store               562 non-null    bool  \n",
      " 14  Google              562 non-null    bool  \n",
      " 15  Android             562 non-null    bool  \n",
      " 16  Droid               562 non-null    bool  \n",
      " 17  Circles             562 non-null    bool  \n",
      " 18  Blogger             562 non-null    bool  \n",
      " 19  Maps                562 non-null    bool  \n",
      " 20  Company             562 non-null    object\n",
      " 21  Company by Product  10 non-null     object\n",
      " 22  Not Matching        562 non-null    object\n",
      "dtypes: bool(16), object(7)\n",
      "memory usage: 43.9+ KB\n"
     ]
    }
   ],
   "source": [
    "cut_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 iPad or iPhone App\n",
      "if you're coming to #sxsw be sure to download the sxsw go app, it has all the schedules and locations of the events. {link}\n",
      "\n",
      "1164 iPad or iPhone App\n",
      "check out the new @mention app {link} - this is gonna be huge next week at #sxsw and beyond.\n",
      "\n",
      "1681 iPad or iPhone App\n",
      "@mention #hollergram app is killing it at #sxsw {link}\n",
      "\n",
      "1915 iPad or iPhone App\n",
      "want to make #sxsw film more fun? download #filmaster app {link} check-in to screenings &amp; get private recommendations!\n",
      "\n",
      "2341 iPad or iPhone App\n",
      "@mention check it. rt @mention #sxsw free app festival explorer: find the bands you want to see from your music tastes {link}\n",
      "\n",
      "4202 iPad or iPhone App\n",
      "just downloaded the asddieu app in preparation for #sxsw.  pumped.  you need to check it out  {link} #app #events #networking\n",
      "\n",
      "4534 iPad or iPhone App\n",
      "this is one of the three best apps we've seen at #sxsw {link}\n",
      "\n",
      "5467 iPad or iPhone App\n",
      "@mention one of the must have apps to survive #sxsw {link}  join our #sxswbarcrawl during #sxswi\n",
      "\n",
      "6079 iPad or iPhone App\n",
      "â€°Ã»Ã¯foursquare for bands&quot; just in time for #sxsw {link}\n",
      "\n",
      "6648 iPad or iPhone App\n",
      "woohoo! rt @mention @mention #hollergram app is killing it at #sxsw {link}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Printing the tweets that don't have any of the keywords, but do have a given\n",
    "#label in the Product column.\n",
    "apple_tweets = []\n",
    "for i in noprod:\n",
    "    if cut_tweets.loc[i, 'Product'] in ['iPad or iPhone App', 'Apple']:\n",
    "        apple_tweets.append(i)\n",
    "        print(i, cut_tweets['Product'][i])\n",
    "        print(cut_tweets['Tweet'][i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing as most of these are talking about apps, it is reasonable to say their labeling in the Product column is correct. \n",
    "Also, as I've pointed out elsewhere, it appears even the word *Apple* is ommitted from the tweets, as this tweet reads:\n",
    "\n",
    "\"pop up @mention store in austin.\"\n",
    "\n",
    "Other tweets have referenced an \"pop up Apple store\" without the @ symbol on the Apple. Therefore, I'm going to accept all of these as regarding Apple. Also, just so I can continue to identify what these apps are talking about, I'll add a \"key word\" column for Apple Apps, though it won't work like the other keywords. I will only hand place tweets in this column.\n",
    "\n",
    "For the Apple store one, I'll just hand place that one into the Apple keyword column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(11,'Apps', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Apple</th>\n",
       "      <th>iPad</th>\n",
       "      <th>iPads</th>\n",
       "      <th>iPad2</th>\n",
       "      <th>iPhone</th>\n",
       "      <th>iTunes</th>\n",
       "      <th>...</th>\n",
       "      <th>Store</th>\n",
       "      <th>Google</th>\n",
       "      <th>Android</th>\n",
       "      <th>Droid</th>\n",
       "      <th>Circles</th>\n",
       "      <th>Blogger</th>\n",
       "      <th>Maps</th>\n",
       "      <th>Company</th>\n",
       "      <th>Company by Product</th>\n",
       "      <th>Not Matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>if you're coming to #sxsw be sure to download the sxsw go app, it has all the schedules and locations of the events. {link}</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[if, you, re, coming, to, sxsw, be, sure, to, download, the, sxsw, go, app, it, has, all, the, schedules, and, locations, of, the, events, link]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>check out the new @mention app {link} - this is gonna be huge next week at #sxsw and beyond.</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[check, out, the, new, mention, app, link, this, is, gonna, be, huge, next, week, at, sxsw, and, beyond]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>@mention #hollergram app is killing it at #sxsw {link}</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[mention, hollergram, app, is, killing, it, at, sxsw, link]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>want to make #sxsw film more fun? download #filmaster app {link} check-in to screenings &amp;amp; get private recommendations!</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[want, to, make, sxsw, film, more, fun, download, filmaster, app, link, check, in, to, screenings, amp, get, private, recommendations]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>@mention check it. rt @mention #sxsw free app festival explorer: find the bands you want to see from your music tastes {link}</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[mention, check, it, rt, mention, sxsw, free, app, festival, explorer, find, the, bands, you, want, to, see, from, your, music, tastes, link]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4202</th>\n",
       "      <td>just downloaded the asddieu app in preparation for #sxsw.  pumped.  you need to check it out  {link} #app #events #networking</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[just, downloaded, the, asddieu, app, in, preparation, for, sxsw, pumped, you, need, to, check, it, out, link, app, events, networking]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>this is one of the three best apps we've seen at #sxsw {link}</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[this, is, one, of, the, three, best, apps, we, ve, seen, at, sxsw, link]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467</th>\n",
       "      <td>@mention one of the must have apps to survive #sxsw {link}  join our #sxswbarcrawl during #sxswi</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[mention, one, of, the, must, have, apps, to, survive, sxsw, link, join, our, sxswbarcrawl, during, sxswi]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>â€°Ã»Ã¯foursquare for bands&amp;quot; just in time for #sxsw {link}</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[Ã»Ã¯foursquare, for, bands, quot, just, in, time, for, sxsw, link]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6648</th>\n",
       "      <td>woohoo! rt @mention @mention #hollergram app is killing it at #sxsw {link}</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[woohoo, rt, mention, mention, hollergram, app, is, killing, it, at, sxsw, link]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                              Tweet  \\\n",
       "404     if you're coming to #sxsw be sure to download the sxsw go app, it has all the schedules and locations of the events. {link}   \n",
       "1164                                   check out the new @mention app {link} - this is gonna be huge next week at #sxsw and beyond.   \n",
       "1681                                                                         @mention #hollergram app is killing it at #sxsw {link}   \n",
       "1915     want to make #sxsw film more fun? download #filmaster app {link} check-in to screenings &amp; get private recommendations!   \n",
       "2341  @mention check it. rt @mention #sxsw free app festival explorer: find the bands you want to see from your music tastes {link}   \n",
       "4202  just downloaded the asddieu app in preparation for #sxsw.  pumped.  you need to check it out  {link} #app #events #networking   \n",
       "4534                                                                  this is one of the three best apps we've seen at #sxsw {link}   \n",
       "5467                               @mention one of the must have apps to survive #sxsw {link}  join our #sxswbarcrawl during #sxswi   \n",
       "6079                                                                    â€°Ã»Ã¯foursquare for bands&quot; just in time for #sxsw {link}   \n",
       "6648                                                     woohoo! rt @mention @mention #hollergram app is killing it at #sxsw {link}   \n",
       "\n",
       "                 Product           Emotion  \\\n",
       "404   iPad or iPhone App  Positive emotion   \n",
       "1164  iPad or iPhone App  Positive emotion   \n",
       "1681  iPad or iPhone App  Positive emotion   \n",
       "1915  iPad or iPhone App  Positive emotion   \n",
       "2341  iPad or iPhone App  Positive emotion   \n",
       "4202  iPad or iPhone App  Positive emotion   \n",
       "4534  iPad or iPhone App  Positive emotion   \n",
       "5467  iPad or iPhone App  Positive emotion   \n",
       "6079  iPad or iPhone App  Positive emotion   \n",
       "6648  iPad or iPhone App  Positive emotion   \n",
       "\n",
       "                                                                                                                                                Tokens  \\\n",
       "404   [if, you, re, coming, to, sxsw, be, sure, to, download, the, sxsw, go, app, it, has, all, the, schedules, and, locations, of, the, events, link]   \n",
       "1164                                          [check, out, the, new, mention, app, link, this, is, gonna, be, huge, next, week, at, sxsw, and, beyond]   \n",
       "1681                                                                                       [mention, hollergram, app, is, killing, it, at, sxsw, link]   \n",
       "1915            [want, to, make, sxsw, film, more, fun, download, filmaster, app, link, check, in, to, screenings, amp, get, private, recommendations]   \n",
       "2341     [mention, check, it, rt, mention, sxsw, free, app, festival, explorer, find, the, bands, you, want, to, see, from, your, music, tastes, link]   \n",
       "4202           [just, downloaded, the, asddieu, app, in, preparation, for, sxsw, pumped, you, need, to, check, it, out, link, app, events, networking]   \n",
       "4534                                                                         [this, is, one, of, the, three, best, apps, we, ve, seen, at, sxsw, link]   \n",
       "5467                                        [mention, one, of, the, must, have, apps, to, survive, sxsw, link, join, our, sxswbarcrawl, during, sxswi]   \n",
       "6079                                                                                 [Ã»Ã¯foursquare, for, bands, quot, just, in, time, for, sxsw, link]   \n",
       "6648                                                                  [woohoo, rt, mention, mention, hollergram, app, is, killing, it, at, sxsw, link]   \n",
       "\n",
       "      Apple   iPad  iPads  iPad2  iPhone  iTunes  ...  Store  Google  Android  \\\n",
       "404   False  False  False  False   False   False  ...  False   False    False   \n",
       "1164  False  False  False  False   False   False  ...  False   False    False   \n",
       "1681  False  False  False  False   False   False  ...  False   False    False   \n",
       "1915  False  False  False  False   False   False  ...  False   False    False   \n",
       "2341  False  False  False  False   False   False  ...  False   False    False   \n",
       "4202  False  False  False  False   False   False  ...  False   False    False   \n",
       "4534  False  False  False  False   False   False  ...  False   False    False   \n",
       "5467  False  False  False  False   False   False  ...  False   False    False   \n",
       "6079  False  False  False  False   False   False  ...  False   False    False   \n",
       "6648  False  False  False  False   False   False  ...  False   False    False   \n",
       "\n",
       "      Droid  Circles  Blogger   Maps  Company  Company by Product  \\\n",
       "404   False    False    False  False    Apple               Apple   \n",
       "1164  False    False    False  False    Apple               Apple   \n",
       "1681  False    False    False  False    Apple               Apple   \n",
       "1915  False    False    False  False    Apple               Apple   \n",
       "2341  False    False    False  False    Apple               Apple   \n",
       "4202  False    False    False  False    Apple               Apple   \n",
       "4534  False    False    False  False    Apple               Apple   \n",
       "5467  False    False    False  False    Apple               Apple   \n",
       "6079  False    False    False  False    Apple               Apple   \n",
       "6648  False    False    False  False    Apple               Apple   \n",
       "\n",
       "      Not Matching  \n",
       "404          Match  \n",
       "1164         Match  \n",
       "1681         Match  \n",
       "1915         Match  \n",
       "2341         Match  \n",
       "4202         Match  \n",
       "4534         Match  \n",
       "5467         Match  \n",
       "6079         Match  \n",
       "6648         Match  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in apple_tweets:\n",
    "    noprod.remove(i)\n",
    "    df.at[i,'Company'] = 'Apple'\n",
    "    df.at[i,'Not Matching'] = 'Match'\n",
    "    if i != 2961:\n",
    "        df.at[i,'Apps'] = True\n",
    "    else:\n",
    "        df.at[i,'Apple'] = True\n",
    "\n",
    "df.loc[apple_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing the Uncategorized Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown    552\n",
       "Name: Company, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Company'] == 'Unknown','Company'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still many tweets that have yet to be categorized. What concerns me is that if I add these tweets to the tweets I already deleted because they addressed both companies, then I would delete over 10% of the data, which I'd like to avoid. So, the only alternative is to do further study on these tweets. I'll start with seeing what the most popular words on in these tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mention', 608),\n",
       " ('sxsw', 567),\n",
       " ('link', 499),\n",
       " ('the', 238),\n",
       " ('to', 228),\n",
       " ('at', 179),\n",
       " ('for', 157),\n",
       " ('rt', 108),\n",
       " ('of', 101),\n",
       " ('in', 98),\n",
       " ('you', 89),\n",
       " ('quot', 80),\n",
       " ('and', 74),\n",
       " ('11', 73),\n",
       " ('amp', 72),\n",
       " ('on', 71),\n",
       " ('free', 64),\n",
       " ('is', 60),\n",
       " ('austin', 57),\n",
       " ('re', 50),\n",
       " ('are', 50),\n",
       " ('codes', 47),\n",
       " ('we', 46),\n",
       " ('valid', 46),\n",
       " ('00', 46),\n",
       " ('59', 46),\n",
       " ('03', 46),\n",
       " ('infektd', 46),\n",
       " ('this', 44),\n",
       " ('it', 44),\n",
       " ('sxswi', 43),\n",
       " ('from', 43),\n",
       " ('with', 43),\n",
       " ('not', 42),\n",
       " ('party', 38),\n",
       " ('by', 38),\n",
       " ('59p', 38),\n",
       " ('out', 37),\n",
       " ('app', 35),\n",
       " ('12', 33),\n",
       " ('up', 32),\n",
       " ('check', 30),\n",
       " ('great', 30),\n",
       " ('us', 29),\n",
       " ('music', 29),\n",
       " ('make', 28),\n",
       " ('via', 27),\n",
       " ('here', 27),\n",
       " ('but', 27),\n",
       " ('if', 26),\n",
       " ('my', 26),\n",
       " ('new', 24),\n",
       " ('about', 23),\n",
       " ('10', 23),\n",
       " ('can', 22),\n",
       " ('download', 22),\n",
       " ('your', 22),\n",
       " ('social', 22),\n",
       " ('see', 21),\n",
       " ('today', 21),\n",
       " ('products', 21),\n",
       " ('me', 20),\n",
       " ('edchat', 20),\n",
       " ('musedchat', 20),\n",
       " ('booth', 20),\n",
       " ('plenty', 20),\n",
       " ('newtwitter', 19),\n",
       " ('join', 19),\n",
       " ('or', 19),\n",
       " ('launching', 19),\n",
       " ('any', 19),\n",
       " ('classical', 18),\n",
       " ('rewards', 18),\n",
       " ('thanks', 18),\n",
       " ('our', 18),\n",
       " ('ride', 18),\n",
       " ('get', 18),\n",
       " ('so', 18),\n",
       " ('gt', 17),\n",
       " ('doing', 17),\n",
       " ('no', 17),\n",
       " ('launch', 16),\n",
       " ('come', 16),\n",
       " ('sampler', 16),\n",
       " ('groundlink', 16),\n",
       " ('437', 16),\n",
       " ('now', 16),\n",
       " ('else', 16),\n",
       " ('zlf', 16),\n",
       " ('all', 15),\n",
       " ('Ã£_', 15),\n",
       " ('groupon', 15),\n",
       " ('has', 15),\n",
       " ('hey', 15),\n",
       " ('be', 15),\n",
       " ('red', 15),\n",
       " ('what', 14),\n",
       " ('type', 14),\n",
       " ('living', 14),\n",
       " ('going', 14)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens = []\n",
    "for num in df.loc[df['Company'] == 'Unknown','Company'].index:\n",
    "    new = df.at[num,'Tokens']\n",
    "    for word in new:\n",
    "        all_tokens.append(word)\n",
    "cut_tweet_word_counts = tally(all_tokens)\n",
    "            \n",
    "cut_tweet_word_counts[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I cannot find any other words that clarify which company the tweet addresses. I'm going to have to read through each one and classify them as I go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df.loc[df['Company'] == 'Unknown',['Tweet','Company']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple</th>\n",
       "      <th>Google</th>\n",
       "      <th>Android</th>\n",
       "      <th>Circles</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Apple  Google  Android  Circles Company\n",
       "669   False    True    False     True  Google\n",
       "1858  False    True    False     True  Google\n",
       "3237  False    True     True    False  Google\n",
       "3848   True   False    False    False   Apple\n",
       "4904  False    True    False    False  Google\n",
       "5429  False    True    False     True  Google"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The lists and dictionaries below are hand made after reading through all the\n",
    "#tweets with unknown companies.\n",
    "unknowns = [669, 1858, 3237, 3848, 4904, 5429]\n",
    "new_company_labels = {669 : 'Google', 1858 : 'Google', 3237 : 'Google',\n",
    "3848 : 'Apple', 4904 : 'Google',5429 : 'Google'}\n",
    "\n",
    "#Labeling the companies\n",
    "new_product_labels = {669 : 'Circles', 1858 : 'Circles',\n",
    "                      3237 : 'Android', 5429 : 'Circles'}\n",
    "for i in new_company_labels.keys():\n",
    "    df.at[i,'Company'] = new_company_labels[i]\n",
    "    df.at[i,new_company_labels[i]] = True\n",
    "\n",
    "#Labeling the products\n",
    "for i in new_product_labels.keys():\n",
    "    if new_product_labels[i] == 'Android':\n",
    "        df.at[i,'Android'] = True\n",
    "    if new_product_labels[i] == 'Circles':\n",
    "        df.at[i,'Circles'] = True\n",
    "\n",
    "df.loc[unknowns,['Apple', 'Google', 'Android', 'Circles', 'Company']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple      4506\n",
       "Google     2275\n",
       "Unknown     546\n",
       "Name: Company, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "still_unknown = len(df.loc[df['Company'] == 'Unknown',['Tweet','Company']])\n",
    "df['Company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I deleted 223 tweets because they discussed both Google and Apple.\n",
      "I deleted 2 tweets because the keyword analysis mismatched the given product\n",
      "column.\n",
      "I will now delete 546 tweets that do not specify a company or product.\n",
      "After deleting duplicates, I had 7553 tweets remaining.\n",
      "With the additional 771 tweets described above deleted, I deleted a total of\n",
      "10.21% of the original data.\n"
     ]
    }
   ],
   "source": [
    "new_del = num_both + len(mismatch_products) + still_unknown\n",
    "perc_del = round(new_del / new_tot *10000)/100\n",
    "\n",
    "print('I deleted', num_both, 'tweets because they discussed both',\n",
    "      'Google and Apple.')\n",
    "print('I deleted', len(mismatch_products),\n",
    "      'tweets because the keyword analysis mismatched the given product')\n",
    "print('column.')\n",
    "print('I will now delete', still_unknown, 'tweets that do not specify a',\n",
    "      'company or product.')\n",
    "print('After deleting duplicates, I had', new_tot,'tweets remaining.')\n",
    "print('With the additional', new_del,\n",
    "      'tweets described above deleted, I deleted a total of')\n",
    "print('{}% of the original data.'.format(perc_del))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't want to go higher than 10%, but 0.2% higher is not something to be upset about. I will now drop those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows with no company known.\n",
    "df.drop(index = df.loc[df['Company']=='Unknown'].index, inplace=True)\n",
    "\n",
    "#Resetting the dataset's index.\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing Data\n",
    "Now that I've pruned the data into something usable, I will now begin the task of sorting the data into more delibrate categories. I'll start by creating a cell that lists keywords used in each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    #This first variable will put each word in list format. I'll be able to\n",
    "    #easily alphabetize the words in this form.\n",
    "    keyword_lst = []\n",
    "    #I want this cell to appear as a string, so I'll store each string here.\n",
    "    keyword_string = ''\n",
    "    \n",
    "    #This first function picks the Apple or Google keywords and destination.\n",
    "    if df.at[i,'Company'] == 'Apple':\n",
    "        columns = df.iloc[0:1,4:15].columns\n",
    "        place = 'Apple Keyword'\n",
    "    else:\n",
    "        columns = df.iloc[0:1,15:21].columns\n",
    "        place = 'Google Keyword'\n",
    "    \n",
    "    #This for loop puts the keywords in the correct column and format.\n",
    "    for col in columns:\n",
    "        if df.at[i,col] == True:\n",
    "            keyword_lst.append(col)\n",
    "            \n",
    "    #Alphabetize the list\n",
    "    keyword_lst.sort()\n",
    "    \n",
    "    #Place the words in a string.\n",
    "    for word in keyword_lst:\n",
    "        keyword_string += word + ' '\n",
    "    df.at[i, place] = keyword_string[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPad                         1364\n",
      "iPhone                        967\n",
      "Apple Store                   552\n",
      "Apple                         468\n",
      "Apple Store iPad              268\n",
      "Apple Store iPad2             197\n",
      "iPad iPhone                    84\n",
      "Apple iPad                     84\n",
      "Apple iPad2                    83\n",
      "Store iPhone                   66\n",
      "iTunes                         48\n",
      "Store iPad                     40\n",
      "Apple Store iPads              37\n",
      "iPad iPad2                     34\n",
      "Laptop iPad                    27\n",
      "iPad2                          24\n",
      "Store                          15\n",
      "Apple iPhone                   13\n",
      "Apple iPad iPad2               12\n",
      "Apple Store iPad iPad2         12\n",
      "iPad iPads                     10\n",
      "Apple iPads                    10\n",
      "Laptop iPhone                  10\n",
      "Apps                           10\n",
      "Store iPad2                     8\n",
      "Laptop iPad iPhone              6\n",
      "Apple Store iPhone              5\n",
      "Apple Store iPad iPads          4\n",
      "Store iPad iTunes               4\n",
      "Apple iTunes                    4\n",
      "iPhone iTunes                   3\n",
      "Apple iPad iPhone               3\n",
      "Apple Laptop                    3\n",
      "iPads                           3\n",
      "Apple Store iPad2 iPads         2\n",
      "Store iPad iPhone               2\n",
      "iPads iPhone                    2\n",
      "Store iPad iPad2                2\n",
      "Store iTunes                    2\n",
      "Laptop                          1\n",
      "Apple iPhone iTunes             1\n",
      "iPad iTunes                     1\n",
      "Apple iPad iPads                1\n",
      "Apple iPad iTunes               1\n",
      "iPad2 iPhone                    1\n",
      "Apple iPad2 iPhone              1\n",
      "Apple Laptop iPhone             1\n",
      "Apple Store iPad2 iTunes        1\n",
      "Apple Laptop iPad2              1\n",
      "iTune                           1\n",
      "Store iPad iPads                1\n",
      "Apple iPad2 iPads               1\n",
      "Store iPads                     1\n",
      "Apple Laptop iPad2 iPhone       1\n",
      "Apple Store iTunes              1\n",
      "Apple Laptop iPad iPad2         1\n",
      "iPad2 iTunes                    1\n",
      "Name: Apple Keyword, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Printing the Apple keyword combination counts.\n",
    "print(df['Apple Keyword'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google            1302\n",
      "Circles Google     481\n",
      "Android            293\n",
      "Google Maps        155\n",
      "Android Google      12\n",
      "Circles             12\n",
      "Blogger Google      11\n",
      "Maps                 4\n",
      "Android Droid        2\n",
      "Blogger              2\n",
      "Droid                1\n",
      "Name: Google Keyword, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Printing the Google keyword combination counts.\n",
    "print(df['Google Keyword'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing all the different combinations of keywords, I will broadly bin the keywords into two categories for each company: \"Company Brand\" and \"Company Product\". The reason why I won't bin them further is that in March 2011, the two brands do not always have directly competing products. Google Play Music didn't launch until November 2011. Chromebooks did not exist yet. In 2023, there are only two Google Retail stores. Likewise, Apple Maps didn't release until 2012. As far as I know, Apple has never publicly considered launching a social network or blogging site.\n",
    "\n",
    "So the point is, there are too many products between the two companies that do not compete against each other. Therefore, comparing the two on a product by product basis doesn't make sense.\n",
    "\n",
    "I will classify the tweets about the Apple store as part of the Apple Brand, since a store is not a product itself. A store is the physical space used to sell products, and the final bit of marketing to get people to buy once they have arrived with that purpose in mind. So since a store and a brand are both part of marketing, I'll label tweets about stores as part of the brand. However, if a tweet mentions both the store and any other apple product, I'll label it as a tweet about products.\n",
    "\n",
    "Lastly, I thought about classifying all Google Circles tweets as brand since, in March 2011, Google Circles was mere speculation for it's upcoming social network, that eventually was confirmed to be Google Plus. I decided to leave this category as Google Products because people's speculation about the product reflects what they think of current Google products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell allows me to read through the different combos of keywords. I'll\n",
    "# create two dictionaries that define how each combination of keywords\n",
    "#is categorizized.\n",
    "apple_category = {\n",
    "'iPad': 'Apple Products',\n",
    "'iPhone': 'Apple Products',\n",
    "'Apple Store': 'Apple Brand',\n",
    "'Apple': 'Apple Brand',\n",
    "'Apple Store iPad': 'Apple Products',\n",
    "'Apple Store iPad2': 'Apple Products',\n",
    "'iPad iPhone': 'Apple Products',\n",
    "'Apple iPad': 'Apple Products',\n",
    "'Apple iPad2': 'Apple Products',\n",
    "'Store iPhone': 'Apple Products',\n",
    "'iTunes': 'Apple Products',\n",
    "'Store iPad': 'Apple Products',\n",
    "'Apple Store iPads': 'Apple Products',\n",
    "'iPad iPad2': 'Apple Products',\n",
    "'Laptop iPad': 'Apple Products',\n",
    "'iPad2': 'Apple Products',\n",
    "'Store': 'Apple Brand',\n",
    "'Apple iPhone': 'Apple Products',\n",
    "'Apple Store iPad iPad2': 'Apple Products',\n",
    "'Apple iPad iPad2': 'Apple Products',\n",
    "'Apps': 'Apple Products',\n",
    "'Apple iPads': 'Apple Products',\n",
    "'Laptop iPhone': 'Apple Products',\n",
    "'iPad iPads': 'Apple Products',\n",
    "'Store iPad2': 'Apple Products',\n",
    "'Laptop iPad iPhone': 'Apple Products',\n",
    "'Apple Store iPhone': 'Apple Products',\n",
    "'Apple iTunes': 'Apple Products',\n",
    "'Apple Store iPad iPads': 'Apple Products',\n",
    "'Store iPad iTunes': 'Apple Products',\n",
    "'Apple Laptop': 'Apple Products',\n",
    "'iPads': 'Apple Products',\n",
    "'Apple iPad iPhone': 'Apple Products',\n",
    "'iPhone iTunes': 'Apple Products',\n",
    "'Apple Store iPad2 iPads': 'Apple Products',\n",
    "'Store iPad iPad2': 'Apple Products',\n",
    "'Store iTunes': 'Apple Products',\n",
    "'iPads iPhone': 'Apple Products',\n",
    "'Store iPad iPhone': 'Apple Products',\n",
    "'Apple Store iTunes': 'Apple Products',\n",
    "'iPad2 iTunes': 'Apple Products',\n",
    "'Store iPad iPads': 'Apple Products',\n",
    "'Store iPads': 'Apple Products',\n",
    "'Apple iPad iPads': 'Apple Products',\n",
    "'iTune': 'Apple Products',\n",
    "'Apple iPad2 iPads': 'Apple Products',\n",
    "'iPad2 iPhone': 'Apple Products',\n",
    "'Apple iPad2 iPhone': 'Apple Products',\n",
    "'Apple Store iPad2 iTunes': 'Apple Products',\n",
    "'Apple Laptop iPad2 iPhone': 'Apple Products',\n",
    "'Apple iPhone iTunes': 'Apple Products',\n",
    "'Apple Laptop iPad iPad2': 'Apple Products',\n",
    "'Laptop': 'Apple Products',\n",
    "'Apple Laptop iPad2': 'Apple Products',\n",
    "'Apple Laptop iPhone': 'Apple Products',\n",
    "'Apple iPad iTunes': 'Apple Products',\n",
    "'iPad iTunes': 'Apple Products'}\n",
    "\n",
    "google_category = {\n",
    "'Google': 'Google Brand',\n",
    "'Circles Google': 'Google Products',\n",
    "'Android': 'Google Products',\n",
    "'Google Maps': 'Google Products',\n",
    "'Circles': 'Google Products',\n",
    "'Android Google': 'Google Products',\n",
    "'Blogger Google': 'Google Products',\n",
    "'Maps': 'Google Products',\n",
    "'Blogger': 'Google Products',\n",
    "'Android Droid': 'Google Products',\n",
    "'Droid': 'Google Products'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I now want to put all the keywords into a single column.\n",
    "df.insert(21,'Keywords','')\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df.at[i,'Apple Keyword'] in apple_category:\n",
    "        df.at[i,'Keywords'] = df.at[i,'Apple Keyword']\n",
    "        df.at[i,'Category'] = apple_category[df.at[i,'Apple Keyword']]\n",
    "    else:\n",
    "        df.at[i,'Keywords'] = df.at[i,'Google Keyword']\n",
    "        df.at[i,'Category'] = google_category[df.at[i,'Google Keyword']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple Products     3471\n",
       "Google Brand       1302\n",
       "Apple Brand        1035\n",
       "Google Products     973\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tweet', 'Product', 'Emotion', 'Tokens', 'Apple', 'iPad', 'iPads',\n",
       "       'iPad2', 'iPhone', 'iTunes', 'iPhone5', 'Apps', 'iTune', 'Laptop',\n",
       "       'Store', 'Google', 'Android', 'Droid', 'Circles', 'Blogger', 'Maps',\n",
       "       'Keywords', 'Company', 'Company by Product', 'Not Matching',\n",
       "       'Apple Keyword', 'Google Keyword', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs tweeting at #rise_austin, it was dead!  i need to upgrade. plugin stations at #sxsw.</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[wesley83, have, 3g, iphone, after, hrs, tweeting, at, rise_austin, it, was, dead, need, to, upgrade, plugin, stations, at, sxsw]</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at #sxsw</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[jessedee, know, about, fludapp, awesome, ipad, iphone, app, that, you, ll, likely, appreciate, for, its, design, also, they, re, giving, free, ts, at, sxsw]</td>\n",
       "      <td>iPad iPhone</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. they should sale them down at #sxsw.</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[swonderlin, can, not, wait, for, ipad, also, they, should, sale, them, down, at, sxsw]</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as crashy as this year's iphone app. #sxsw</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[sxsw, hope, this, year, festival, isn, as, crashy, as, this, year, iphone, app, sxsw]</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa mayer (google), tim o'reilly (tech books/conferences) &amp;amp; matt mullenweg (wordpress)</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, on, fri, sxsw, marissa, mayer, google, tim, reilly, tech, books, conferences, amp, matt, mullenweg, wordpress]</td>\n",
       "      <td>Google</td>\n",
       "      <td>Google</td>\n",
       "      <td>Google Brand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         Tweet  \\\n",
       "0              .@wesley83 i have a 3g iphone. after 3 hrs tweeting at #rise_austin, it was dead!  i need to upgrade. plugin stations at #sxsw.   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/iphone app that you'll likely appreciate for its design. also, they're giving free ts at #sxsw   \n",
       "2                                                              @swonderlin can not wait for #ipad 2 also. they should sale them down at #sxsw.   \n",
       "3                                                           @sxsw i hope this year's festival isn't as crashy as this year's iphone app. #sxsw   \n",
       "4          @sxtxstate great stuff on fri #sxsw: marissa mayer (google), tim o'reilly (tech books/conferences) &amp; matt mullenweg (wordpress)   \n",
       "\n",
       "            Emotion  \\\n",
       "0  Negative emotion   \n",
       "1  Positive emotion   \n",
       "2  Positive emotion   \n",
       "3  Negative emotion   \n",
       "4  Positive emotion   \n",
       "\n",
       "                                                                                                                                                          Tokens  \\\n",
       "0                              [wesley83, have, 3g, iphone, after, hrs, tweeting, at, rise_austin, it, was, dead, need, to, upgrade, plugin, stations, at, sxsw]   \n",
       "1  [jessedee, know, about, fludapp, awesome, ipad, iphone, app, that, you, ll, likely, appreciate, for, its, design, also, they, re, giving, free, ts, at, sxsw]   \n",
       "2                                                                        [swonderlin, can, not, wait, for, ipad, also, they, should, sale, them, down, at, sxsw]   \n",
       "3                                                                         [sxsw, hope, this, year, festival, isn, as, crashy, as, this, year, iphone, app, sxsw]   \n",
       "4                       [sxtxstate, great, stuff, on, fri, sxsw, marissa, mayer, google, tim, reilly, tech, books, conferences, amp, matt, mullenweg, wordpress]   \n",
       "\n",
       "      Keywords Company        Category  \n",
       "0       iPhone   Apple  Apple Products  \n",
       "1  iPad iPhone   Apple  Apple Products  \n",
       "2         iPad   Apple  Apple Products  \n",
       "3       iPhone   Apple  Apple Products  \n",
       "4       Google  Google    Google Brand  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Many of the columns have been created exclusively to categorize the tweets.\n",
    "#Now that the categorization is complete, I no longer need these columns.\n",
    "#Also, I no longer need the given Products column.\n",
    "#So I'll save this work in a separate DataFrame and trim df to only the columns\n",
    "#I need for the NLP analysis.\n",
    "df_keywords = df.copy()\n",
    "df = df.loc[:,['Tweet', 'Emotion', 'Tokens',\n",
    "               'Keywords', 'Company', 'Category']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Targets\n",
    "Now that I have the data I want, I need to set some targets for each. I'll set this to eight targets, two for each category, both negative and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No emotion toward brand or product    3743\n",
      "Positive emotion                      2432\n",
      "Negative emotion                       476\n",
      "Name: Emotion, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product - Apple Products     1727\n",
       "Positive emotion - Apple Products                       1395\n",
       "No emotion toward brand or product - Google Brand        834\n",
       "No emotion toward brand or product - Google Products     608\n",
       "No emotion toward brand or product - Apple Brand         574\n",
       "Positive emotion - Apple Brand                           371\n",
       "Positive emotion - Google Brand                          369\n",
       "Positive emotion - Google Products                       297\n",
       "Negative emotion - Apple Products                        281\n",
       "Negative emotion - Google Brand                           75\n",
       "Negative emotion - Apple Brand                            72\n",
       "Negative emotion - Google Products                        48\n",
       "Name: Target Text, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dict = {\n",
    "\"Negative emotion - Apple Brand\" : 111,\n",
    "\"Negative emotion - Apple Products\" : 112,\n",
    "\"Negative emotion - Google Brand\" : 121,\n",
    "\"Negative emotion - Google Products\" : 122,\n",
    "\"No emotion toward brand or product - Apple Brand\" : 211,\n",
    "\"No emotion toward brand or product - Apple Products\" : 212,\n",
    "\"No emotion toward brand or product - Google Brand\" : 221,\n",
    "\"No emotion toward brand or product - Google Products\" : 222,\n",
    "\"Positive emotion - Apple Brand\" : 311,\n",
    "\"Positive emotion - Apple Products\" : 312,\n",
    "\"Positive emotion - Google Brand\" : 321,\n",
    "\"Positive emotion - Google Products\" : 322,\n",
    "\"I can't tell - Apple Brand\" : 411,\n",
    "\"I can't tell - Apple Products\" : 412,\n",
    "\"I can't tell - Google Brand\" : 421,\n",
    "\"I can't tell - Google Products\" : 412}\n",
    "\n",
    "emotion_num = {\n",
    "'Negative emotion' : 100, \n",
    "'No emotion toward brand or product' : 200, \n",
    "'Positive emotion' : 300, \n",
    "\"I can't tell\" : 400}\n",
    "\n",
    "category_num = {\n",
    "'Apple Brand' : 11, \n",
    "'Apple Products' : 12, \n",
    "'Google Brand' : 21, \n",
    "'Google Products' : 22}\n",
    "\n",
    "df['Target'] = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df.at[i,'Target Text'] = df.at[i,'Emotion'] + ' - ' + df.at[i,'Category']\n",
    "    df.at[i,'Target'] = (emotion_num[df.at[i,'Emotion']] + \n",
    "                         category_num[df.at[i,'Category']])\n",
    "\n",
    "print(df['Emotion'].value_counts())\n",
    "df.loc[:,'Target Text'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the deletions, there are still 130 tweets with an unusable emotion label. I'll need to delete those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows with no company known.\n",
    "df.drop(index = df.loc[df['Target'] > 400].index, inplace=True)\n",
    "\n",
    "#Resetting the dataset's index.\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No emotion toward brand or product    3743\n",
      "Positive emotion                      2432\n",
      "Negative emotion                       476\n",
      "Name: Emotion, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product - Apple Products     1727\n",
       "Positive emotion - Apple Products                       1395\n",
       "No emotion toward brand or product - Google Brand        834\n",
       "No emotion toward brand or product - Google Products     608\n",
       "No emotion toward brand or product - Apple Brand         574\n",
       "Positive emotion - Apple Brand                           371\n",
       "Positive emotion - Google Brand                          369\n",
       "Positive emotion - Google Products                       297\n",
       "Negative emotion - Apple Products                        281\n",
       "Negative emotion - Google Brand                           75\n",
       "Negative emotion - Apple Brand                            72\n",
       "Negative emotion - Google Products                        48\n",
       "Name: Target Text, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['Emotion'].value_counts())\n",
    "df.loc[:,'Target Text'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm impressed. This is nigh perfect. I'll trust this function more in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Distributions for all the tweets.\n",
    "\n",
    "Now I need to make my first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def visualize_top_10(freq_dist, title):\n",
    "\n",
    "    # Extract data for plotting\n",
    "    top_10 = list(zip(*freq_dist.most_common(10)))\n",
    "    tokens = top_10[0]\n",
    "    counts = top_10[1]\n",
    "\n",
    "    # Set up plot and plot data\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(tokens, counts)\n",
    "\n",
    "    # Customize plot appearance\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    \n",
    "sample_freq_dist = FreqDist(df['Tokens'].explode())\n",
    "visualize_top_10(sample_freq_dist, \n",
    "                 'Top 10 Word Frequency for the Entire Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_twelve_subplots():\n",
    "    fig = plt.figure(figsize=(9,12))\n",
    "    fig.set_tight_layout(True)\n",
    "    gs = fig.add_gridspec(4, 3)\n",
    "    ax1  = fig.add_subplot(gs[0, 0])\n",
    "    ax2  = fig.add_subplot(gs[0, 1])\n",
    "    ax3  = fig.add_subplot(gs[0, 2])\n",
    "    ax4  = fig.add_subplot(gs[1, 0])\n",
    "    ax5  = fig.add_subplot(gs[1, 1])\n",
    "    ax6  = fig.add_subplot(gs[1, 2])\n",
    "    ax7  = fig.add_subplot(gs[2, 0])\n",
    "    ax8  = fig.add_subplot(gs[2, 1])\n",
    "    ax9  = fig.add_subplot(gs[2, 2])\n",
    "    ax10 = fig.add_subplot(gs[3, 0])\n",
    "    ax11 = fig.add_subplot(gs[3, 1])\n",
    "    ax12 = fig.add_subplot(gs[3, 2])\n",
    "    return fig, [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[111, 'Negative emotion - Apple Brand'],\n",
       " [112, 'Negative emotion - Apple Products'],\n",
       " [121, 'Negative emotion - Google Brand'],\n",
       " [122, 'Negative emotion - Google Products'],\n",
       " [211, 'No emotion toward brand or product - Apple Brand'],\n",
       " [212, 'No emotion toward brand or product - Apple Products'],\n",
       " [221, 'No emotion toward brand or product - Google Brand'],\n",
       " [222, 'No emotion toward brand or product - Google Products'],\n",
       " [311, 'Positive emotion - Apple Brand'],\n",
       " [312, 'Positive emotion - Apple Products'],\n",
       " [321, 'Positive emotion - Google Brand'],\n",
       " [322, 'Positive emotion - Google Products']]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list = []\n",
    "for index, category in zip(df['Target'].unique(), df['Target Text'].unique()):\n",
    "    target_list.append([index, category])\n",
    "\n",
    "repeat = 1\n",
    "while repeat == 1:\n",
    "    again = 0\n",
    "    for i in range(len(target_list)-1):\n",
    "        if target_list[i][0] > target_list[i+1][0]:\n",
    "            target_list[i], target_list[i+1] = target_list[i+1], target_list[i]\n",
    "            again = 1\n",
    "    if again == 0:\n",
    "        repeat = 0\n",
    "target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 Negative emotion - Apple Brand\n",
      "112 Negative emotion - Apple Products\n",
      "121 Negative emotion - Google Brand\n",
      "122 Negative emotion - Google Products\n",
      "211 No emotion toward brand or product - Apple Brand\n",
      "212 No emotion toward brand or product - Apple Products\n",
      "221 No emotion toward brand or product - Google Brand\n",
      "222 No emotion toward brand or product - Google Products\n",
      "311 Positive emotion - Apple Brand\n",
      "312 Positive emotion - Apple Products\n",
      "321 Positive emotion - Google Brand\n",
      "322 Positive emotion - Google Products\n"
     ]
    }
   ],
   "source": [
    "def plots(column, axes, title=\"Word Frequency for\"):\n",
    "    for index, category in target_list:\n",
    "        # Calculate frequency distribution for this subset\n",
    "        all_words = df[df[\"Target\"] == index][column].explode()\n",
    "        freq_dist = FreqDist(all_words)\n",
    "        top_10 = list(zip(*freq_dist.most_common(10)))\n",
    "        tokens = top_10[0]\n",
    "        counts = top_10[1]\n",
    "\n",
    "        # Set up plot\n",
    "        ax = axes[index]\n",
    "        ax.bar(tokens, counts)\n",
    "\n",
    "        # Customize plot appearance\n",
    "        ax.set_title(f\"{title} {category}\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.tick_params(axis=\"x\", rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sdgfasrhgdfgbertg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-608c3f1d6051>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msdgfasrhgdfgbertg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sdgfasrhgdfgbertg' is not defined"
     ]
    }
   ],
   "source": [
    "sdgfasrhgdfgbertg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = setup_twelve_subplots()\n",
    "plots(\"Tokens\", axes)\n",
    "fig.suptitle(\"Word Frequencies for All Tokens\", fontsize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into Train and Test sets\n",
    "I will use the 80/20 split for Train vs Test sets of data. I will split each target listed above by this same ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating the Test/Train split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df.iloc[:,0:-1],df.iloc[:,-1], train_size=.8, random_state = 42)\n",
    "\n",
    "#I'm paranoid that the function will somehow pick few of one of the less common\n",
    "#targets and then won't recognize it in the test. So I will test to see how\n",
    "#close the ratio between train/test split is to the specified 0.8 train size\n",
    "#for each target.\n",
    "\n",
    "for tar in y_train.unique():\n",
    "    train_size = y_train.value_counts()[tar]\n",
    "    test_size = y_test.value_counts()[tar]\n",
    "    train_perc = round(train_size/(train_size + test_size),3)\n",
    "    print(tar, train_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove NAs for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df_No_NAs = df_raw['emotion_in_tweet_is_directed_at'].notna()\n",
    "df_to_trim = df['Product'].notna()\n",
    "df_test = df[df_to_trim]\n",
    "df_nan = df[~df_to_trim]\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the train and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll make two sets of train/test data, one for the raw data, the other for scaled numerica data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = df['churn']\n",
    "#X = df.drop(['phone number', 'churn'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_scl = df_scl['churn']\n",
    "#X_scl = df_scl.drop(['phone number', 'churn'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_scl, X_test_scl, y_train_scl, y_test_scl = train_test_split(\n",
    "#    X_scl, y_scl, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Name of First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason for choosing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions for Morgan:\n",
    "1. What should my Train Test split percentages be?\n",
    "Typically 9000 stick to 20/25 for test.\n",
    "\n",
    "What are the words that arise out of the positive or negative tweets that arise often? What services do people write about positively and negatively?\n",
    "\n",
    "Write about how to use this model for the benefit. An actionable recommendation.\n",
    "\n",
    "\n",
    "2. My steps are:\n",
    "    1. Define the 5800 tweets as either Apple, Google, or delete them.\n",
    "    2. Split data into Apple & Google Tweets. This will involve a word search seeing what key words are included in the tweet (Products and company names)\n",
    "    3. Put it all in lower case.\n",
    "    3a. Remove HTML, URLs, clean up mentions by deleting all @ symbols.\n",
    "    4. Tokenize everything / evaluate frequencies\n",
    "    5. Build a baseline model with TfidfVectorizer and MultinomialNB\n",
    "    5a. Account Vectorizor\n",
    "    6. The final NLP lab lists the next five considerations. I'm honestly a little puzzled by them at first glance as I did this a few months ago.\n",
    "    * Do we remove stop words or not?\n",
    "    * What should be counted as a token? Do we stem or lemmatize our text data, or leave the words as is? Do we want to include non-\"words\" in our tokens?\n",
    "    * Do we engineer other features, such as bigrams, or POS tags, or Mutual Information Scores?\n",
    "    * Do we use the entire vocabulary, or just limit the model to a subset of the most frequently used words? If so, how many?\n",
    "    * What sort of vectorization should we use in our model? Boolean Vectorization? Count Vectorization? TF-IDF? More advanced vectorization strategies such as Word2Vec?\n",
    "    \n",
    "Target is part of the model.\n",
    "The projects will require us to have a target for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
